{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rule Learning\n",
    "\n",
    "The next topic to cover is association rule learning. The prototypical example of association rule learning is when Amazon or another online retailer shows a list of \"Customers who bought this item also bought...\" In other words, given some set of data, can we find some other data that is \"like it\". We will cover only one kind of algorithm for doing this sort of computation: apriori.\n",
    "\n",
    "# Apriori\n",
    "\n",
    "The apriori algorithm is a way to take in data and generate a list of association rules. Let's take for example a Netflix movie recommendor. We want to look at all of our users data and try to figure out what movies a particular user might like based on what they have seen. For example, consider a user Jim. Jim just watched *The Dark Knight*. We know from our vast collection of data that people who watched *The Dark Knight* usually also watch *Deadpool* so logically we would recommend *Deadpool* to Jim. Continuing with our Netflix example, let us break down how the parts of the algorithm, but you will notice it looks a bit similiar to the Naive Bayes algorithm from our classification section. \n",
    "\n",
    "1. The first step of the algorithm is the *support* step. Given some movie *x*, the support for *x* is given as $support(x)=\\frac{\\text{number of users watching x}}{\\text{total number of users}}$\n",
    "2. The next step is the *confidence* step. Given two movies, *x* and *y*, we can calculate the confidence of *y* given *x* as $confidence(y|x)=\\frac{\\text{numbers of users who have seen both x and y}}{\\text{number of users who have seen x}}$\n",
    "3. The final computation is the *lift*. Again, given two movies *x* and *y*, the lift of *y* given *x* is $lift(y|x)=\\frac{confidence(y|x)}{support(y)}$\n",
    "\n",
    "Using these parts, we can actually build our algorithm.\n",
    "\n",
    "1. Set a minimum support and confidence.\n",
    "2. Take all the subsets in transactions having higher support than minimum support.\n",
    "3. Take all the rules of these subsets having confidence higher than the minimum confidence.\n",
    "4. Sort results by decreasing lift. \n",
    "\n",
    "Now we are going to use this algorithm to solve a new business problem. This business problem is optimizing the sales in a grocery store. Our dataset is simply a bunch of rows where each row contains the full order of an individual customer. Using this data, we want to try and find some rules that will help us better organize our store such that things that people often buy together are new each other. This is going to be a bit different from what we have done before in that we cannot just import a library to do what we need to do, this had to be written manually is a file called *apyori.py*. This file contains methods needed to parse data and calculate things like lift and confidence for our specific business problem. We will not go over this code, but you should be able to figure out what it does just by looking at it. The first step is to read in the data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data Preprocessing\n",
    "dataset = pd.read_csv('data/Market_Basket_Optimisation.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to correctly use the *apyori* fuction, we need to pass it in a list that contains the list of each transaction (a list of lists). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transactions = []\n",
    "for i in range(0, 7501):\n",
    "    transactions.append([str(dataset.values[i,j]) for j in range(0, 20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our list of lists, we can actually make our model and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'light cream'}) :  frozenset({'chicken'})  :  4.84395061728395\n",
      "\n",
      "\n",
      "frozenset({'mushroom cream sauce'}) :  frozenset({'escalope'})  :  3.790832696715049\n",
      "\n",
      "\n",
      "frozenset({'pasta'}) :  frozenset({'escalope'})  :  4.700811850163794\n",
      "\n",
      "\n",
      "frozenset({'fromage blanc'}) :  frozenset({'honey'})  :  5.164270764485569\n",
      "\n",
      "\n",
      "frozenset({'herb & pepper'}) :  frozenset({'ground beef'})  :  3.2919938411349285\n",
      "\n",
      "\n",
      "frozenset({'tomato sauce'}) :  frozenset({'ground beef'})  :  3.840659481324083\n",
      "\n",
      "\n",
      "frozenset({'light cream'}) :  frozenset({'olive oil'})  :  3.1147098515519573\n",
      "\n",
      "\n",
      "frozenset({'whole wheat pasta'}) :  frozenset({'olive oil'})  :  4.122410097642296\n",
      "\n",
      "\n",
      "frozenset({'pasta'}) :  frozenset({'shrimp'})  :  4.506672147735896\n",
      "\n",
      "\n",
      "frozenset({'spaghetti', 'avocado'}) :  frozenset({'milk'})  :  3.215449245541838\n",
      "\n",
      "\n",
      "frozenset({'milk', 'cake'}) :  frozenset({'burgers'})  :  3.211437308868501\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from apyori import apriori\n",
    "rules = apriori(transactions, min_support = 0.003, min_confidence = 0.2, min_lift = 3, min_length = 2)\n",
    "\n",
    "# Visualising the results\n",
    "results = list(rules)\n",
    "\n",
    "# Print out the most relevant results\n",
    "i = 0\n",
    "for item in results:\n",
    "    print(item.ordered_statistics[0].items_base, \": \", item.ordered_statistics[0].items_add, \" : \", item.ordered_statistics[0].lift)\n",
    "    print(\"\\n\")\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The output of each line of result shows the base item(s) first, the item associated with the base item, and the lift value. So for the first line we read as \"people who bought light cream were also likely to buy chicken\". The lift value is a good indicator of what this likelihood is, and a lift value greater than 3 is typically seen as good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
