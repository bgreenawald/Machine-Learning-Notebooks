{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Many a time, instead of needing to predict a continuous variable, we may desire to predict a variable that has descrete values. In other words, we need to classify a new data point into one of a finite number of categories. The archetypical example for this kind of problem is a spam filter. Giant companies like Google and Microsoft who host email services need to have some sort of spam filter to block out unnecessary emails from there users. So, given some new email, we need to decide whether or not the email is spam. Like the problems we have seen so far, emails will need to have some *features*. Recall that features are just ways to describe an object. So far our email example, some features (word count, number of capitalized words, ect), can we train a machine learning models that decides what features decide whether an email is spam or not. This is the premise of classification. \n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "One of the most important classification machine learning models is the logistic regression. The problem setup for logistic regression goes like this. Given some sets of data whose dependent variables is binary (two categories, usually yes or no), can we fit a function that gives us the probability that a new observation fall into one of the categories. This is where the logistic regression comes in. One thing you may have noticed right of the bat it that it is called logistic *regression*. Didn't we just finish regression? Well, yes. We are doing regression here, but it is only an intermediary step. Our regression curve represents the probabilties of falling into a given category. Let us make this concrete with an example which comes from the Wikipedia page on logistic regression (https://en.wikipedia.org/wiki/Logistic_regression). Our data set consists of the amount of hours a student spent studying and whether or not they passed the exam. We want to predict based on the number of hours studying if a student passed or not. Notice that our dependent variable is binary (they either passed, or they didn't). We are going to fit a curve that represents the probability that a student passed based on the number of ours they studied. This curve is shown below:\n",
    "![log_reg](log_reg.jpg)\n",
    "Again, note that the y-axis is the probability that a student passed given their score. Note that this is still not a classification problem. To turn it into one, we simply have a cutoff probability. 50% is a common cutoff. So if our regression line gives us a value of 0.5 or higher, then we say that a student passed. This cutoff score is up to the machine learning engineer. We would like to not get into too much math, but let us quickly go over the math. We are more than familiar with the linear regression equation, $y = B_0 + B_1x$. To apply logistic regression, we apply the sigmoid function to this data. The sigmoid function is has that *S* shape we saw in the example above and in general, the formula is $S(x) = \\frac{1}{1+e^{-x}}$. Converting it to our notation, we get $p(x) = \\frac{1}{1+e^{-x}}$ where *p* is the probability of being in the \"yes\" or '1' class. Note that the sigmoid function is bounded by 0 and 1, which is good because a probability must always be in the interval $[0,1]$. Solving the equation, we get $log(\\frac{p}{1-p}) = B_0+B_1x$, which is what is solved to get our curve.\n",
    "\n",
    "Let us use all of this to make an actual logistic regression model. The data for this example is social media ad data. We are trying to decide based on a users age and salary if they bought the product for some advertisment. First we import our data, fit our logistic regression on the train set, and make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Student\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "X = dataset.iloc[:, [2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our predictions, we need to see how accurately our model performed. Since we have our predictions for the test set, as well as the actual results from the test set, we can compare how these two sets match up. This is generally done in what is called a confusion matrix. This following picture of a confusion matrix (from rasbt.github.io), is an excellent visualization of the confusion matrix.\n",
    "![confusion_matrix](confusion_matrix.jpg)\n",
    "This matrix breaks down not only how accurate our model was, but where the model was accurate, and where it messed up. This is why cofusion matrices are much more descriptive that accuracy alone. In python, the confusion matrix is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  3]\n",
      " [ 8 24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can match up this matrix with the image above to analyze our data. For example, we can see that our number of true positives (or the number of times our model guessed that a user would respond to the add, and then they did) was 65. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
